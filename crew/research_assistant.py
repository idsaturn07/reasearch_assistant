import os
import time
import logging
from typing import List

from dotenv import load_dotenv
from crewai import Agent, Task, Crew
from langchain_openai import ChatOpenAI
from diskcache import Cache
import gradio as gr

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

if not os.path.exists('crew.env'):
    with open('crew.env', 'w') as f:
        f.write('OPENAI_API_KEY=your-api-key-here\n')
    logger.warning("‚ö†Ô∏è Created crew.env file - please add your OpenAI API key")

load_dotenv('crew.env')

class ResearchCrew:
    def __init__(self, model: str = "gpt-3.5-turbo", temperature: float = 0.5):
        self._validate_api_key()
        self.llm = self._init_llm(model, temperature)
        logger.info("ü§ñ Research Crew Initialized")

    def _validate_api_key(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key or api_key == "your-api-key-here":
            raise ValueError(
                "‚ùå Missing OpenAI API key\n"
                "1. Get your key from https://platform.openai.com/account/api-keys\n"
                "2. Add it to crew.env file as: OPENAI_API_KEY=your-key-here"
            )

    def _init_llm(self, model: str, temperature: float):
        return ChatOpenAI(
            model=model,
            temperature=temperature,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            request_timeout=30
        )

    def _create_agents(self):
        return [
            Agent(
                role='Senior Research Analyst',
                goal='Find reliable, fact-checked information',
                backstory="""Expert researcher with 10+ years experience in academic and market research.""",
                verbose=False,
                allow_delegation=False,
                llm=self.llm
            ),
            Agent(
                role='Technical Content Strategist',
                goal='Write professional reports from research data',
                backstory="""Skilled writer who makes complex ideas accessible.""",
                verbose=False,
                allow_delegation=False,
                llm=self.llm
            )
        ]

    def _create_tasks(self, topic: str) -> List[Task]:
        agents = self._create_agents()
        return [
            Task(
                description=f"Research the topic: {topic}",
                expected_output="Concise summary with sources.",
                agent=agents[0]
            ),
            Task(
                description=f"Create a report on {topic} with sections: Intro, Key Findings, Analysis",
                expected_output="500-800 word markdown report.",
                agent=agents[1]
            )
        ]

    def generate_report(self, topic: str) -> str:
        start_time = time.time()
        try:
            crew = Crew(
                agents=self._create_agents(),
                tasks=self._create_tasks(topic),
                verbose=False
            )
            result = crew.kickoff()
            logger.info(f"‚úÖ Report generated in {time.time() - start_time:.2f} seconds")
            return self._format_report(topic, result)
        except Exception as e:
            logger.error(f"‚ùå Error during report generation: {str(e)}")
            return f"‚ö†Ô∏è Research Error: {str(e)}"

    def _format_report(self, topic: str, content: str) -> str:
        return f"# üìä Research Report: {topic.title()}\n\n{content}\n\n*Report generated by AI.*"

cache = Cache("research_cache", size_limit=1000000)

def get_cached_report(topic: str, model: str, temperature: float, progress=gr.Progress()) -> str:
    cache_key = f"{topic}_{model}_{temperature}"
    if cache_key in cache:
        progress(1.0, desc="Loading from cache")
        return cache[cache_key]

    try:
        progress(0.1, desc="Setting up research team...")
        crew = ResearchCrew(model, temperature)
        progress(0.4, desc="Conducting research...")
        report = crew.generate_report(topic)
        cache.set(cache_key, report, expire=86400)
        progress(1.0, desc="Done!")
        return report
    except Exception as e:
        return f"‚ùå Error: {str(e)}"

def create_interface():
    with gr.Blocks(title="ü§ñ AI Research Assistant") as interface:
        gr.Markdown("## üß† AI-Powered Research Assistant")
        with gr.Row():
            with gr.Column():
                topic = gr.Textbox(label="Enter a research topic")
                with gr.Accordion("‚öôÔ∏è Advanced", open=False):
                    model = gr.Dropdown(["gpt-3.5-turbo", "gpt-4-turbo"], value="gpt-3.5-turbo", label="Model")
                    temperature = gr.Slider(0, 1, value=0.5, step=0.1, label="Creativity")
                submit = gr.Button("Generate Report")
            with gr.Column():
                report = gr.Markdown(label="Generated Report")

        submit.click(
            fn=get_cached_report,
            inputs=[topic, model, temperature],
            outputs=report,
            show_progress="minimal"
        )

        gr.Examples(
            examples=[["AI in Agriculture"], ["Future of Robotics"], ["Renewable Energy Trends"]],
            inputs=topic
        )

    return interface

def launch_app():
    interface = create_interface()
    for port in range(7861, 7871):  
        try:
            logger.info(f"üöÄ Launching on port {port}")
            interface.launch(
                server_name="127.0.0.1",
                server_port=port,
                quiet=False,
                show_error=True
            )
            return
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Port {port} unavailable: {e}")
    logger.error("‚ùå No available port found. Try closing apps using ports 7861‚Äì7870.")

if __name__ == "__main__":
    launch_app()